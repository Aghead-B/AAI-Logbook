{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from random import randint\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a corpus of 41701 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"hazes.txt\") as corpus_file:\n",
    "    corpus = corpus_file.read()\n",
    "    corpus = corpus.lower()\n",
    "print(\"Loaded a corpus of {0} characters\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 20, 128)           86016     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20, 64)            49408     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 20, 64)            33024     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 20, 64)            33024     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 39)                2535      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 39)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237,031\n",
      "Trainable params: 237,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Build our network from loaded architecture and weights\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "with open('model.json', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "model = model_from_json(data)\n",
    "\n",
    "\n",
    "model.load_weights('weights-20.hdf5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a unique identifier for each char in the corpus, then make some dicts to ease encoding and decoding\n",
    "chars = sorted(list(set(corpus)))\n",
    "num_chars = len(chars)\n",
    "encoding = {c: i for i, c in enumerate(chars)}\n",
    "decoding = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "  if temperature <= 0:\n",
    "    return np.argmax(preds)\n",
    "  preds = np.asarray(preds).astype('float64')\n",
    "  preds = np.log(preds) / temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate(seed_pattern):\n",
    "        X = np.zeros((1, sentence_length, num_chars), dtype=bool)\n",
    "        #print(X.shape)\n",
    "        for i, character in enumerate(seed_pattern):\n",
    "            X[0, i, encoding[character]] = 1\n",
    "        \n",
    "        generated_text = \"\"\n",
    "        for i in range(500):\n",
    "            # even de temperatuur toevoegen.\n",
    "            prediction = sample(model.predict(X, verbose=0)[0],0.5)\n",
    "            generated_text += decoding[prediction]\n",
    "\n",
    "            activations = np.zeros((1, 1, num_chars), dtype=bool)\n",
    "            activations[0, 0, prediction] = 1\n",
    "            X = np.concatenate((X[:, 1:, :], activations), axis=1)\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "def make_seed(seed_phrase=\"\"):\n",
    "        if seed_phrase:\n",
    "            phrase_length = len(seed_phrase)\n",
    "            pattern = \"\"\n",
    "            for i in range (0, sentence_length):\n",
    "                pattern += seed_phrase[i % phrase_length]\n",
    "        else:\n",
    "            seed = randint(0, corpus_length - sentence_length)\n",
    "            pattern = abba_corpus[seed:seed + sentence_length]\n",
    "\n",
    "        return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ik ben blij en ik je\n",
      " nooit meer taop\n",
      "tot mij tu liefen\n",
      "de legt dat is een verdeen\n",
      "dat jij ne snaal\n",
      "toe ik jou niet meer anler van mij\n",
      "het is wat jij niet onlen staat\n",
      "met ik jou niet dat ik verdeen\n",
      "want ik hou naoie ondiet\n",
      "maar ik verdeen\n",
      "noar os een je niet genoef\n",
      "ik hieg met jij nu niet ze vrrrrtwe tij\n",
      "\n",
      "met is verdt mee,\n",
      "maar ik gaat me hier lonen mij verleen\n",
      "maar de wat jij mag laar weer ondeen veiegen\n",
      "ons jij nu niet garhen\n",
      "maar nooit maar geven\n",
      "die ik moet alleen boor jou staat\n",
      "met ik vrar ne elleen\n",
      "\n",
      "ik heb nie\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 20\n",
    "seed = make_seed('ik ben blij en ik je')\n",
    "print(seed)\n",
    "txt =  generate(seed)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample song\n",
    "In the bard and show you on your lovelight and i can't get the mowner i'm a marion an and every mind, there's a boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
